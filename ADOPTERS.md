# Adopters

Organisations and individuals using or adapting the AI Runtime Behaviour Security.

---

## Why List Adopters?

- **Credibility:** Shows real-world applicability
- **Community:** Connects practitioners facing similar challenges
- **Feedback:** Helps improve the framework based on experience
- **Accountability:** Public commitment encourages follow-through

---

## How to Be Listed

Submit a pull request adding your organisation to the appropriate section, or open an issue with:

1. Organisation name (or "Anonymous" if preferred)
2. Industry sector
3. Brief description of how you're using the framework
4. Contact (optional â€” for others who want to discuss)

**We welcome:**
- Full adopters implementing the framework
- Partial adopters using specific components
- Evaluators assessing the framework for future use
- Contributors improving the framework

---

## Adopters

*None yet. Be the first.*

### Template

```markdown
### [Organisation Name]

**Industry:** [Sector]
**Using Since:** [Date]
**Components:** [e.g., Risk Tiers, Judge Pattern, Full Framework]
**Contact:** [Optional]

Brief description of how you're using the framework and any adaptations made.
```

---

## Evaluating

Organisations currently evaluating the framework.

*None listed.*

---

## Contributors

Individuals and organisations who have contributed improvements.

*See [GitHub contributors](https://github.com/JonathanCGill/ai-runtime-behaviour-security/graphs/contributors)*

---

## Share Your Experience

If you're using this framework, we'd love to hear:

- What worked well?
- What needed adaptation?
- What's missing?
- What would you change?

Open an issue or submit feedback via pull request. Your experience helps everyone.

---

## Disclaimer

Listing here doesn't imply endorsement of the framework by the organisation, nor endorsement of the organisation by the framework maintainers. It simply indicates use or evaluation.
---

*AI Runtime Behaviour Security, 2026 (Jonathan Gill).*
